{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"11V9TSBigUtkqgta2X62gwG9OVtgGHjCD","timestamp":1685324694632}],"gpuType":"T4","mount_file_id":"11V9TSBigUtkqgta2X62gwG9OVtgGHjCD","authorship_tag":"ABX9TyPW0aiHugvYoTZSF7f3CyK0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jlw1aA-rXN3M","executionInfo":{"status":"ok","timestamp":1685320707039,"user_tz":-120,"elapsed":18799,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}},"outputId":"aa1f2b54-5129-4fe6-dccb-bad0ddd8a1e2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["import torch\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","import glob\n","import PIL.Image\n","import os\n","import numpy as np"],"metadata":{"id":"CvVUgJbaXViz","executionInfo":{"status":"ok","timestamp":1685320877224,"user_tz":-120,"elapsed":5092,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/ImageDataset/\n","!unzip -q road_following.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iLK5Vn-9YcKq","executionInfo":{"status":"ok","timestamp":1685321149539,"user_tz":-120,"elapsed":20776,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}},"outputId":"f35f91b7-3cc5-4140-968a-bf2e31e41938"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ImageDataset\n"]}]},{"cell_type":"code","source":["def get_x(path, width):\n","    \"\"\"Gets the x value from the image filename\"\"\"\n","    return (float(int(path.split(\"_\")[0])) - width/2) / (width/2)\n","\n","def get_y(path, height):\n","    \"\"\"Gets the y value from the image filename\"\"\"\n","    return (float(int(path.split(\"_\")[1])) - height/2) / (height/2)\n","\n","class XYDataset(torch.utils.data.Dataset):\n","    \n","    def __init__(self, directory, random_hflips=False):\n","        self.directory = directory\n","        self.random_hflips = random_hflips\n","        self.image_paths = glob.glob(os.path.join(self.directory, '*.jpg'))\n","        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n","    \n","    def __len__(self):\n","        return len(self.image_paths)\n","    \n","    def __getitem__(self, idx):\n","        image_path = self.image_paths[idx]\n","        \n","        image = PIL.Image.open(image_path)\n","        width, height = image.size\n","        x = float(get_x(os.path.basename(image_path), width))\n","        y = float(get_y(os.path.basename(image_path), height))\n","      \n","        if float(np.random.rand(1)) > 0.5:\n","            image = transforms.functional.hflip(image)\n","            x = -x\n","                    \n","        image = self.color_jitter(image)\n","        image = transforms.functional.resize(image, (224, 224))\n","        image = transforms.functional.to_tensor(image)\n","        image = image.numpy()[::-1].copy()\n","        image = torch.from_numpy(image)\n","        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        \n","        return image, torch.tensor([x, y]).float()\n","\n","dataset = XYDataset('/content/drive/MyDrive/', random_hflips=False)\n"],"metadata":{"id":"Z8goyexdXf0W","executionInfo":{"status":"ok","timestamp":1685321856646,"user_tz":-120,"elapsed":234,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["test_percent = 0.2\n","num_test = int(test_percent * len(dataset))\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])"],"metadata":{"id":"poh0pIDgX2kq","executionInfo":{"status":"ok","timestamp":1685321859728,"user_tz":-120,"elapsed":255,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader(\n","    train_dataset,\n","    batch_size=5,\n","    shuffle=True,\n","    num_workers=0\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset,\n","    batch_size=5,\n","    shuffle=True,\n","    num_workers=0\n",")"],"metadata":{"id":"LBqPSj5LX8-x","executionInfo":{"status":"ok","timestamp":1685321862122,"user_tz":-120,"elapsed":260,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = models.resnet18(pretrained=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8G2ZdRwQa3qq","executionInfo":{"status":"ok","timestamp":1685321874297,"user_tz":-120,"elapsed":6917,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}},"outputId":"50dadf9d-6302-4f49-bd0a-fae34018818a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n","100%|██████████| 44.7M/44.7M [00:05<00:00, 8.29MB/s]\n"]}]},{"cell_type":"code","source":["model.fc = torch.nn.Linear(512, 2)\n","device = torch.device('cuda')\n","model = model.to(device)"],"metadata":{"id":"_JJIJQS9a6cl","executionInfo":{"status":"ok","timestamp":1685323291163,"user_tz":-120,"elapsed":238,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["NUM_EPOCHS = 30\n","BEST_MODEL_PATH = 'best_steering_model_xy.pth'\n","best_loss = 1e9\n","\n","optimizer = optim.Adam(model.parameters())\n","\n","for epoch in range(NUM_EPOCHS):\n","    \n","    model.train()\n","    train_loss = 0.0\n","    for images, labels in iter(train_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = F.mse_loss(outputs, labels)\n","        train_loss += float(loss)\n","        loss.backward()\n","        optimizer.step()\n","    train_loss /= len(train_loader)\n","    \n","    model.eval()\n","    test_loss = 0.0\n","    for images, labels in iter(test_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        outputs = model(images)\n","        loss = F.mse_loss(outputs, labels)\n","        test_loss += float(loss)\n","    test_loss /= len(test_loader)\n","    \n","    print('%f, %f' % (train_loss, test_loss))\n","    if test_loss < best_loss:\n","        torch.save(model.state_dict(), BEST_MODEL_PATH)\n","        best_loss = test_loss"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v5yG5nrYbAbJ","executionInfo":{"status":"ok","timestamp":1685324304752,"user_tz":-120,"elapsed":7097,"user":{"displayName":"Suhrut Heroorkar","userId":"17797723381556607937"}},"outputId":"24cf8536-d205-4818-a82c-cb3cb7a03ce5"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["0.067633, 0.184324\n","0.079771, 0.127409\n","0.070099, 0.190233\n","0.079302, 0.226598\n","0.025942, 0.046051\n","0.025920, 0.031366\n","0.042419, 0.038520\n","0.025799, 0.031097\n","0.023879, 0.052205\n","0.012774, 0.039900\n","0.025500, 0.010572\n","0.015536, 0.050474\n","0.018457, 0.011021\n","0.004218, 0.024048\n","0.028129, 0.007116\n","0.012509, 0.021073\n","0.009762, 0.012023\n","0.012682, 0.085355\n","0.019933, 0.019919\n","0.012397, 0.016080\n","0.025357, 0.008913\n","0.031923, 0.014016\n","0.027446, 0.073985\n","0.017223, 0.030181\n","0.018496, 0.011211\n","0.013714, 0.021166\n","0.013419, 0.011442\n","0.013623, 0.038818\n","0.011217, 0.041207\n","0.014492, 0.011549\n"]}]}]}